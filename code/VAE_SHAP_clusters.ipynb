{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb692ee5-4d24-4148-ae45-3243700d625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/usr/local/lib/python3.10/dist-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/usr/local/lib/python3.10/dist-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22fb4af-b456-45ee-ad08-54df20017c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f17170-e23a-436a-bd15-1dcc4ed2ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "from scipy import sparse\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8d17c3e-db36-4829-950d-f261715685b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"VAE\" ### Can be MLP, VAE\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9e302-c311-4beb-94f6-c6db1b63ee77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### VAE recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a249c32-13e9-4324-97e4-3f4994a452e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, model_conf, **kw):\n",
    "        super(VAE, self).__init__()\n",
    "        self.device = kw['device'] \n",
    "        num_features = kw['num_features'] \n",
    "        num_items = kw['num_items'] \n",
    "        self.num_items = num_items\n",
    "        self.enc_dims = [self.num_items] + model_conf['enc_dims']\n",
    "        self.dec_dims = self.enc_dims[::-1]\n",
    "        self.dims = self.enc_dims + self.dec_dims[1:]\n",
    "        self.dropout = model_conf['dropout']\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.total_anneal_steps = model_conf['total_anneal_steps']\n",
    "        self.anneal_cap = model_conf['anneal_cap']\n",
    "\n",
    "        self.eps = 1e-6\n",
    "        self.anneal = 0.\n",
    "        self.update_count = 0\n",
    "        \n",
    "        self.encoder = nn.ModuleList()\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.enc_dims[:-1], self.enc_dims[1:])):\n",
    "            if i == len(self.enc_dims[:-1]) - 1:\n",
    "                d_out *= 2\n",
    "            self.encoder.append(nn.Linear(d_in, d_out))\n",
    "            if i != len(self.enc_dims[:-1]) - 1:\n",
    "                self.encoder.append(nn.ReLU())\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dec_dims[:-1], self.dec_dims[1:])):\n",
    "            self.decoder.append(nn.Linear(d_in, d_out))\n",
    "            if i != len(self.dec_dims[:-1]) - 1:\n",
    "                self.decoder.append(nn.ReLU())\n",
    "                \n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, rating_matrix):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        :param rating_matrix: rating matrix\n",
    "        \"\"\"\n",
    "        # encoder\n",
    "        # Convert the PyTorch tensor to a NumPy array\n",
    "        \n",
    "        #if len(rating_matrix.shape) == 1:\n",
    "        #    rating_matrix = torch.unsqueeze(torch.tensor(rating_matrix), 0)\n",
    "    \n",
    "        #rating_matrix_np = rating_matrix.numpy()\n",
    "\n",
    "        # Normalize along the last dimension using NumPy\n",
    "        #rating_matrix_np_normalized = rating_matrix_np / np.linalg.norm(rating_matrix_np, axis=-1, keepdims=True)\n",
    "\n",
    "        # Convert the normalized NumPy array back to a PyTorch tensor\n",
    "        #h = F.dropout(torch.tensor(rating_matrix_np_normalized), p=self.dropout, training=self.training)\n",
    "        if len(rating_matrix.shape) == 1:\n",
    "            rating_matrix = torch.unsqueeze(torch.tensor(rating_matrix), 0)\n",
    "        h = F.dropout(F.normalize(rating_matrix, dim=-1), p=self.dropout, training=self.training)\n",
    "        for layer in self.encoder:\n",
    "            h = layer(h)\n",
    "\n",
    "        # sample\n",
    "        mu_q = h[:, :self.enc_dims[-1]]\n",
    "        logvar_q = h[:, self.enc_dims[-1]:]  # log sigmod^2  batch x 200\n",
    "        std_q = torch.exp(0.5 * logvar_q)  # sigmod batch x 200\n",
    "        \n",
    "        epsilon = torch.zeros_like(std_q).normal_(mean=0, std=0.01)\n",
    "        sampled_z = mu_q + self.training * epsilon * std_q\n",
    "\n",
    "        output = sampled_z\n",
    "        for layer in self.decoder:\n",
    "            output = layer(output)\n",
    "\n",
    "        if self.training:\n",
    "            kl_loss = ((0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)).mean()\n",
    "            return output, kl_loss\n",
    "        else:\n",
    "            if self.demographic:\n",
    "                return self.softmax(output[:,:self.items_only])\n",
    "            else:\n",
    "                return self.softmax(output)   \n",
    "        \n",
    "    def train_one_epoch(self, dataset, optimizer, batch_size, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Train model for one epoch\n",
    "        :param dataset: given data\n",
    "        :param optimizer: choice of optimizer\n",
    "        :param batch_size: batch size\n",
    "        :return: model loss\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "\n",
    "        train_matrix = dataset\n",
    "\n",
    "        num_training = train_matrix.shape[0]\n",
    "        num_batches = int(np.ceil(num_training / batch_size))\n",
    "        perm = np.random.permutation(num_training)\n",
    "\n",
    "        loss = 0.0\n",
    "        for b in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if (b + 1) * batch_size >= num_training:\n",
    "                batch_idx = perm[b * batch_size:]\n",
    "            else:\n",
    "                batch_idx = perm[b * batch_size: (b + 1) * batch_size]\n",
    "            batch_matrix = torch.FloatTensor(train_matrix[batch_idx]).to(self.device)\n",
    "\n",
    "            if self.total_anneal_steps > 0:\n",
    "                self.anneal = min(self.anneal_cap, 1. * self.update_count / self.total_anneal_steps)\n",
    "            else:\n",
    "                self.anneal = self.anneal_cap\n",
    "\n",
    "            pred_matrix, kl_loss = self.forward(batch_matrix)\n",
    "\n",
    "            # cross_entropy\n",
    "            total_ce = -(F.log_softmax(pred_matrix, 1) * batch_matrix)\n",
    "            ce_hist = total_ce[:,:self.num_items].sum(1).mean()\n",
    "            ce_demo = total_ce[:,self.num_items:].sum(1).mean()\n",
    "            ce_loss = ce_hist+alpha*ce_demo\n",
    "\n",
    "            batch_loss = ce_loss + kl_loss * self.anneal\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.update_count += 1\n",
    "\n",
    "            loss += batch_loss\n",
    "            if b % 200 == 0:\n",
    "                print('(%3d / %3d) loss = %.4f' % (b, num_batches, batch_loss))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, eval_users, test_batch_size):\n",
    "        \"\"\"\n",
    "        Predict the model on test set\n",
    "        :param eval_users: evaluation (test) user\n",
    "        :param eval_pos: position of the evaluated (test) item\n",
    "        :param test_batch_size: batch size for test set\n",
    "        :return: predictions\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            input_matrix = torch.Tensor(eval_users).to(self.device)\n",
    "            preds = np.zeros_like(input_matrix.cpu())\n",
    "\n",
    "            num_data = input_matrix.shape[0]\n",
    "            num_batches = int(np.ceil(num_data / test_batch_size))\n",
    "            perm = list(range(num_data))\n",
    "            for b in range(num_batches):\n",
    "                if (b + 1) * test_batch_size >= num_data:\n",
    "                    batch_idx = perm[b * test_batch_size:]\n",
    "                else:\n",
    "                    batch_idx = perm[b * test_batch_size: (b + 1) * test_batch_size]\n",
    "                    \n",
    "                test_batch_matrix = input_matrix[batch_idx]\n",
    "                batch_pred_matrix = self.forward(test_batch_matrix)\n",
    "                batch_pred_matrix.masked_fill(test_batch_matrix.bool(), float('-inf'))\n",
    "                preds[batch_idx] = batch_pred_matrix.detach().cpu().numpy()\n",
    "        return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d109e029-c0fd-4cbc-9c10-2322dbd3bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperModel(nn.Module):\n",
    "    def __init__(self, model, item_array, cluster_to_items, item_to_cluster, num_items, device,num_clusters=10):\n",
    "        super(WrapperModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.n_items = num_items\n",
    "        self.cluster_to_items = cluster_to_items\n",
    "        self.item_to_cluster = item_to_cluster\n",
    "        self.item_array = item_array\n",
    "        self.device = device\n",
    "        self.n_clusters = num_clusters\n",
    "    \n",
    "    def forward(self, input_array):\n",
    "        batch_size = input_array.shape[0]  # Get the batch size (number of users)\n",
    "        user_vector_batch = torch.zeros(batch_size, self.n_items).to(self.device)\n",
    "\n",
    "        for cluster in range(self.n_clusters-1):\n",
    "            cluster_indices = self.cluster_to_items[cluster]\n",
    "            user_vector_batch[:, cluster_indices] = torch.from_numpy(input_array[:, cluster]).unsqueeze(1).float().to(self.device)\n",
    "\n",
    "        model_output_batch = self.model(user_vector_batch)\n",
    "        softmax_output_batch = torch.softmax(model_output_batch[0], dim=1)\n",
    "\n",
    "        cluster_scores_per_user = []\n",
    "\n",
    "    \n",
    "        for user in range(batch_size):\n",
    "            user_cluster_scores = []\n",
    "            # Compute cluster scores for each cluster\n",
    "            for cluster, items in self.cluster_to_items.items():\n",
    "                cluster_scores = softmax_output_batch[user, items]\n",
    "                avg_score = torch.mean(cluster_scores)\n",
    "                user_cluster_scores.append(avg_score)\n",
    "            cluster_scores_per_user.append(torch.stack(user_cluster_scores))\n",
    "\n",
    "        cluster_scores_per_user = torch.stack(cluster_scores_per_user)\n",
    "\n",
    "        return cluster_scores_per_user.cpu().detach().numpy()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = torch.Tensor(x).to(self.device)\n",
    "        output = self.forward(x)\n",
    "        output = torch.Tensor(output).to(device)\n",
    "        return self.model(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66c4d93e-dbf5-4e62-9349-86cdf23e834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\"\n",
    "}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155\n",
    "}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362\n",
    "}\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_0.0002_32_12.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\")\n",
    "}\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): [512,128],\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): [512,128],\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "\n",
    "    (\"Pinterest\",\"VAE\"): [512,128],\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184b2eb-4b83-41f9-85ea-4ff05e51e174",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e88175d0-d540-4ed4-8607-9fac7108b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf26e1df-546e-41b3-a3c0-2aafd3da12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "num_features = num_items_dict[data_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ab96b4a-be4a-4b07-9c6e-d4727e56c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83191fc8-bc90-4eb7-98e3-e8744f656996",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "          'num_features':num_features,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83b470a8-d4cd-4836-9a7a-4f5e4ae430fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a8344a9-8faa-4d3b-a3aa-987e96c7f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f547dcf8-fd78-4fe4-8fe5-be733ef1327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14279ca7-e27e-4c92-939d-f32080c86f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        recommender = VAE(VAE_config, **kw_dict)\n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "    return recommender\n",
    "    \n",
    "model = load_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b5eeef1-e7f2-4fcc-a8b4-0bd20e7c1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(VAE_config ,**kw_dict)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "781ab326-f44e-499a-9f86-31316499963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99068cb0-964d-487e-a868-cd087283f401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_train.shape  torch.Size([4829, 3381])\n",
      "v_train.shape  torch.Size([3381, 3381])\n"
     ]
    }
   ],
   "source": [
    "K = 100\n",
    "u_train = torch.tensor(train_array).float()\n",
    "v_train = all_items_tensor\n",
    "user_ids = np.arange(train_array.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f932393-f7c0-41ad-b651-d67969055b5b",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b19ef80-9420-460a-add1-37701f7681c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "# Cluster items using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "k = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "clusters = kmeans.fit_predict(np.transpose(u_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83450799-723c-4702-96df-e6bac066d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_clusters = kmeans.predict(np.transpose(u_train))\n",
    "\n",
    "# Create mapping from items to clusters\n",
    "item_to_cluster = {}\n",
    "# Create mapping from clusters to items\n",
    "cluster_to_items = {}\n",
    "for i, cluster in enumerate(item_clusters):\n",
    "    item_to_cluster[i] = cluster\n",
    "    if(cluster not in cluster_to_items.keys()):\n",
    "        cluster_to_items[cluster] = []\n",
    "    cluster_to_items[cluster].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25707482-0712-48c8-8a7d-51a072b97390",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = torch.tensor(test_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43a537ef-c86a-4a16-9421-47bfe6a669e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d0764fa-a2da-4d7f-8432-9c490796284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d147441-28cf-4fd5-b8d7-0cc108bc5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_bin =  np.where(user_to_clusters > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "224823cf-fb89-4867-bebb-c5110504ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_train = np.zeros((u_train.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5bdad198-bf47-4386-beaa-10ce7bb0affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_train[:,i] = np.sum(u_train.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f40a299d-0707-4e36-b80c-a46ca2931257",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_clusters_train_bin =  np.where(user_to_clusters_train > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e58106a-04d2-48c3-9ffd-268ac2e4b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_model = WrapperModel(model, items_array, cluster_to_items, item_to_cluster, num_items, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f4bb2-79ba-476b-a433-c58ed73ba0c5",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b71c9f9b-6da6-474c-bcde-06f863f2cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbeabb5c-44f3-442d-b4da-42e117989ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_subset = shap.sample(user_to_clusters_train_bin,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01fd790e-2faa-40ce-8675-cbb7d62a5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(wrap_model,sampled_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5a0d53d-1a7d-480c-8c1b-983e5f27d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89682dccf03945c887277c9dabbd141e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values_test = explainer.shap_values(user_to_clusters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8944f1e3-ceac-4d73-afe8-5671dcac8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_shap = np.mean(shap_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "730d7a56-7070-4e70-a417-2046af2f5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = np.arange(test_array.shape[0]) + train_array.shape[0]\n",
    "input_test_array = np.insert(average_shap, 0, col1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d9b302ae-f7b7-44e1-8650-0107bd13e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(item_to_cluster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "94af2cc0-3efa-4f74-9a88-7f89d6bf0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'shap_values_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(input_test_array, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
